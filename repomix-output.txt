This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-01-07T20:08:16.974Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
public/
  file.svg
  globe.svg
  next.svg
  vercel.svg
  window.svg
src/
  app/
    api/
      ask/
        route.ts
    components/
      ShoeIcon.jsx
    globals.css
    layout.tsx
    page.tsx
  lib/
    get_python_path.ts
    main.py
    process_transcripts.py
    query_cache.py
    shoe_advisor.py
    vector_store.py
    youtube_transcript_getter.py
.gitignore
.python-version
eslint.config.mjs
hello.py
next.config.ts
package.json
postcss.config.mjs
pyproject.toml
README.md
tailwind.config.ts
tsconfig.json
uv.lock

================================================================
Repository Files
================================================================

================
File: public/file.svg
================
<svg fill="none" viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg"><path d="M14.5 13.5V5.41a1 1 0 0 0-.3-.7L9.8.29A1 1 0 0 0 9.08 0H1.5v13.5A2.5 2.5 0 0 0 4 16h8a2.5 2.5 0 0 0 2.5-2.5m-1.5 0v-7H8v-5H3v12a1 1 0 0 0 1 1h8a1 1 0 0 0 1-1M9.5 5V2.12L12.38 5zM5.13 5h-.62v1.25h2.12V5zm-.62 3h7.12v1.25H4.5zm.62 3h-.62v1.25h7.12V11z" clip-rule="evenodd" fill="#666" fill-rule="evenodd"/></svg>

================
File: public/globe.svg
================
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><g clip-path="url(#a)"><path fill-rule="evenodd" clip-rule="evenodd" d="M10.27 14.1a6.5 6.5 0 0 0 3.67-3.45q-1.24.21-2.7.34-.31 1.83-.97 3.1M8 16A8 8 0 1 0 8 0a8 8 0 0 0 0 16m.48-1.52a7 7 0 0 1-.96 0H7.5a4 4 0 0 1-.84-1.32q-.38-.89-.63-2.08a40 40 0 0 0 3.92 0q-.25 1.2-.63 2.08a4 4 0 0 1-.84 1.31zm2.94-4.76q1.66-.15 2.95-.43a7 7 0 0 0 0-2.58q-1.3-.27-2.95-.43a18 18 0 0 1 0 3.44m-1.27-3.54a17 17 0 0 1 0 3.64 39 39 0 0 1-4.3 0 17 17 0 0 1 0-3.64 39 39 0 0 1 4.3 0m1.1-1.17q1.45.13 2.69.34a6.5 6.5 0 0 0-3.67-3.44q.65 1.26.98 3.1M8.48 1.5l.01.02q.41.37.84 1.31.38.89.63 2.08a40 40 0 0 0-3.92 0q.25-1.2.63-2.08a4 4 0 0 1 .85-1.32 7 7 0 0 1 .96 0m-2.75.4a6.5 6.5 0 0 0-3.67 3.44 29 29 0 0 1 2.7-.34q.31-1.83.97-3.1M4.58 6.28q-1.66.16-2.95.43a7 7 0 0 0 0 2.58q1.3.27 2.95.43a18 18 0 0 1 0-3.44m.17 4.71q-1.45-.12-2.69-.34a6.5 6.5 0 0 0 3.67 3.44q-.65-1.27-.98-3.1" fill="#666"/></g><defs><clipPath id="a"><path fill="#fff" d="M0 0h16v16H0z"/></clipPath></defs></svg>

================
File: public/next.svg
================
<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 394 80"><path fill="#000" d="M262 0h68.5v12.7h-27.2v66.6h-13.6V12.7H262V0ZM149 0v12.7H94v20.4h44.3v12.6H94v21h55v12.6H80.5V0h68.7zm34.3 0h-17.8l63.8 79.4h17.9l-32-39.7 32-39.6h-17.9l-23 28.6-23-28.6zm18.3 56.7-9-11-27.1 33.7h17.8l18.3-22.7z"/><path fill="#000" d="M81 79.3 17 0H0v79.3h13.6V17l50.2 62.3H81Zm252.6-.4c-1 0-1.8-.4-2.5-1s-1.1-1.6-1.1-2.6.3-1.8 1-2.5 1.6-1 2.6-1 1.8.3 2.5 1a3.4 3.4 0 0 1 .6 4.3 3.7 3.7 0 0 1-3 1.8zm23.2-33.5h6v23.3c0 2.1-.4 4-1.3 5.5a9.1 9.1 0 0 1-3.8 3.5c-1.6.8-3.5 1.3-5.7 1.3-2 0-3.7-.4-5.3-1s-2.8-1.8-3.7-3.2c-.9-1.3-1.4-3-1.4-5h6c.1.8.3 1.6.7 2.2s1 1.2 1.6 1.5c.7.4 1.5.5 2.4.5 1 0 1.8-.2 2.4-.6a4 4 0 0 0 1.6-1.8c.3-.8.5-1.8.5-3V45.5zm30.9 9.1a4.4 4.4 0 0 0-2-3.3 7.5 7.5 0 0 0-4.3-1.1c-1.3 0-2.4.2-3.3.5-.9.4-1.6 1-2 1.6a3.5 3.5 0 0 0-.3 4c.3.5.7.9 1.3 1.2l1.8 1 2 .5 3.2.8c1.3.3 2.5.7 3.7 1.2a13 13 0 0 1 3.2 1.8 8.1 8.1 0 0 1 3 6.5c0 2-.5 3.7-1.5 5.1a10 10 0 0 1-4.4 3.5c-1.8.8-4.1 1.2-6.8 1.2-2.6 0-4.9-.4-6.8-1.2-2-.8-3.4-2-4.5-3.5a10 10 0 0 1-1.7-5.6h6a5 5 0 0 0 3.5 4.6c1 .4 2.2.6 3.4.6 1.3 0 2.5-.2 3.5-.6 1-.4 1.8-1 2.4-1.7a4 4 0 0 0 .8-2.4c0-.9-.2-1.6-.7-2.2a11 11 0 0 0-2.1-1.4l-3.2-1-3.8-1c-2.8-.7-5-1.7-6.6-3.2a7.2 7.2 0 0 1-2.4-5.7 8 8 0 0 1 1.7-5 10 10 0 0 1 4.3-3.5c2-.8 4-1.2 6.4-1.2 2.3 0 4.4.4 6.2 1.2 1.8.8 3.2 2 4.3 3.4 1 1.4 1.5 3 1.5 5h-5.8z"/></svg>

================
File: public/vercel.svg
================
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1155 1000"><path d="m577.3 0 577.4 1000H0z" fill="#fff"/></svg>

================
File: public/window.svg
================
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 2.5h13v10a1 1 0 0 1-1 1h-11a1 1 0 0 1-1-1zM0 1h16v11.5a2.5 2.5 0 0 1-2.5 2.5h-11A2.5 2.5 0 0 1 0 12.5zm3.75 4.5a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5M7 4.75a.75.75 0 1 1-1.5 0 .75.75 0 0 1 1.5 0m1.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5" fill="#666"/></svg>

================
File: src/app/api/ask/route.ts
================
import { NextResponse } from 'next/server';
import { spawn } from 'child_process';
import { resolve } from 'path';
import { getPythonPath } from '@/lib/get_python_path';

export async function POST(request: Request) {
  try {
    const { question } = await request.json();

    if (!question || typeof question !== 'string') {
      return NextResponse.json(
        { error: 'Invalid question format' },
        { status: 400 }
      );
    }

    // Get Python path from venv
    const pythonPath = getPythonPath();

    // Path to Python script relative to api route
    const pythonScriptPath = resolve(process.cwd(), 'src/lib/shoe_advisor.py');
    
    console.log('Using Python from:', pythonPath);
    console.log('Running script:', pythonScriptPath);
    console.log('Question:', question);

    // Spawn Python process
    const pythonProcess = spawn(pythonPath, [pythonScriptPath, question], {
      stdio: ['pipe', 'pipe', 'pipe'],
      cwd: process.cwd()
    });

    return new Promise((resolve, reject) => {
      let stdoutData = '';
      let stderrData = '';

      pythonProcess.stdout.on('data', (data) => {
        stdoutData += data.toString();
        console.log('Python stdout:', data.toString());
      });

      pythonProcess.stderr.on('data', (data) => {
        stderrData += data.toString();
        console.error('Python stderr:', data.toString());
      });

      pythonProcess.on('error', (err) => {
        console.error('Process error:', err);
        reject(new Error(`Failed to start Python process: ${err.message}`));
      });

      pythonProcess.on('close', (code) => {
        console.log('Python process closed with code:', code);
        console.log('Final stdout:', stdoutData);
        console.log('Final stderr:', stderrData);

        if (code !== 0) {
          return reject(new Error(`Python process exited with code ${code}: ${stderrData}`));
        }

        // Try to find valid JSON in the output
        try {
          const trimmedOutput = stdoutData.trim();
          if (!trimmedOutput) {
            throw new Error('No output from Python script');
          }

          const parsedResult = JSON.parse(trimmedOutput);
          resolve(NextResponse.json(parsedResult));
        } catch (e) {
          console.error('Parse error:', e);
          console.error('Raw stdout:', stdoutData);
          console.error('Raw stderr:', stderrData);
          reject(new Error('Failed to parse Python output. Check server logs for details.'));
        }
      });
    });
  } catch (error) {
    console.error('Request error:', error);
    return NextResponse.json(
      { 
        error: 'Failed to process request', 
        details: error instanceof Error ? error.message : 'Unknown error',
        type: error.constructor.name
      },
      { status: 500 }
    );
  }
}

================
File: src/app/components/ShoeIcon.jsx
================
// components/ShoeIcon.jsx
export const ShoeIcon = ({ size = 20, className = "" }) => (
    <svg 
      width={size} 
      height={size} 
      viewBox="0 0 1024 1024" 
      className={className}
      xmlns="http://www.w3.org/2000/svg"
    >
      <path d="M803.59 850.55q-171.78 6.55-271.24-38.67C437.64 758.61 294.1 664.59 121.91 549q-41.55-36.78-11.27-109.8l65.27 38.52-65.27-41.35q81.06-152.29 169-247.78c41.22-44 101.13-100.05 146.48 0 25.9 73.88 90.16 73.88 146.48 78.84 72-5 90.44-28.46 101.41 45.05 8.86 70.65 68.31 243.43 214.09 349.15 80.09 68.5 82.49 122 45.07 168.94q-36.77 38.94-129.58 19.98z" fill="currentColor" />
      <path d="M724 462.76c34.09 68.38 87 143 164.11 198.91 80.09 68.5 82.49 122 45.07 168.94q-42 44.4-157 13.42-38.44-16.53-84.81-39.74L167.59 472.48q49.3-82.41 120.3-160.94c22.85-25.28 80.61-80.77 114.94-17.8 31.83 58.37 99 36.21 145.49 40.3 59.47-4.1 123.27-10.85 132.33 49.82 2.14 17.14 18.41 45.4 43.35 78.9z" fill="currentColor" opacity="0.2" />
      <path d="M543.2 265c9.89 1 19.77 1.66 29.43 2.51 72-5 90.44-28.46 101.41 45.05 8.86 70.65 68.31 243.43 214.09 349.15 80.09 68.5 82.49 122 45.07 168.94q-49.48 52.31-200.26 0L187.4 485q428.72 190.21 532.72 190.21 121 0-166-257.44A960.15 960.15 0 0 1 543.2 265z" fill="currentColor" opacity="0.1" />
    </svg>
  );
  
  export default ShoeIcon;

================
File: src/app/globals.css
================
@tailwind base;
@tailwind components;
@tailwind utilities;

:root {
  --background: #ffffff;
  --foreground: #171717;
}

@media (prefers-color-scheme: dark) {
  :root {
    --background: #0a0a0a;
    --foreground: #ededed;
  }
}

body {
  color: var(--foreground);
  background: var(--background);
  font-family: Arial, Helvetica, sans-serif;
}

================
File: src/app/layout.tsx
================
import type { Metadata } from "next";
import { Geist, Geist_Mono } from "next/font/google";
import "./globals.css";

const geistSans = Geist({
  variable: "--font-geist-sans",
  subsets: ["latin"],
});

const geistMono = Geist_Mono({
  variable: "--font-geist-mono",
  subsets: ["latin"],
});

export const metadata: Metadata = {
  title: "Running Shoe Advisor",
  description: "Vini's shoe advisor",
};

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en">
      <body
        className={`${geistSans.variable} ${geistMono.variable} antialiased`}
      >
        {children}
      </body>
    </html>
  );
}

================
File: src/app/page.tsx
================
"use client"

import React, { useState } from 'react';
import { Loader2, ExternalLink } from 'lucide-react';
import { ShoeIcon } from './components/ShoeIcon';

interface Recommendation {
  model: string;
  description: string;
}

interface Source {
  title: string;
  video_id: string;
}

function hasRecommendations(text: string): boolean {
  return text.includes('**') && text.includes('-');
}

function parseResponse(text: string): Recommendation[] {
  if (!hasRecommendations(text)) {
    return [];
  }

  const sections = text.split('\n');
  const recommendations: Recommendation[] = [];
  let currentModel = '';
  
  for (const section of sections) {
    const trimmedSection = section.trim();
    if (trimmedSection.startsWith('-') && trimmedSection.includes('**')) {
      const modelMatch = trimmedSection.match(/\*\*(.*?)\*\*/);
      if (modelMatch) {
        currentModel = modelMatch[1].trim();
      }
    } else if (trimmedSection.startsWith('-') && currentModel) {
      const description = trimmedSection.replace(/^-\s*/, '').trim();
      recommendations.push({
        model: currentModel,
        description: description
      });
      currentModel = '';
    }
  }

  return recommendations;
}

export default function Home() {
  const [query, setQuery] = useState('');
  const [recommendations, setRecommendations] = useState<Recommendation[]>([]);
  const [data, setData] = useState<{answer: string, sources: Source[]} | null>(null);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState('');

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    if (!query.trim()) return;

    setLoading(true);
    setError('');
    setRecommendations([]);
    setData(null);
    
    try {
      const res = await fetch('/api/ask', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ question: query }),
      });
      
      const responseData = await res.json();
      
      if (responseData.error) {
        setError(responseData.error);
        return;
      }
      
      setData(responseData);
      const parsed = parseResponse(responseData.answer);
      setRecommendations(parsed);
    } catch (err) {
      setError('Failed to get recommendations. Please try again.');
    } finally {
      setLoading(false);
    }
  };

  return (
    <main className="min-h-screen bg-[#2D3047] px-4 py-12 font-mono lowercase flex flex-col">
      {/* Title Section */}
      <div className="max-w-2xl mx-auto text-center mb-12">
        <h1 className="text-5xl font-bold mb-4 text-[#FF9F1C]">
          running shoe finder
        </h1>
        <p className="text-[#E4D9FF] text-lg">
          enter your favorite shoes. discover your next pair.
        </p>
      </div>

      {/* Search Section */}
      <div className="max-w-xl mx-auto mb-32">
        <form onSubmit={handleSubmit} className="flex gap-3">
          <input
            type="text"
            value={query}
            onChange={(e) => setQuery(e.target.value)}
            placeholder="nike pegasus, brooks ghost..."
            className="flex-1 px-6 py-4 rounded-full border-2 border-[#FF9F1C] bg-[#1F2132] text-white placeholder:text-[#E4D9FF]/50 focus:outline-none focus:ring-2 focus:ring-[#FF9F1C] focus:border-transparent"
            disabled={loading}
          />
          <button
            type="submit"
            disabled={loading}
            className="group px-8 py-4 bg-[#FF9F1C] text-[#2D3047] rounded-full hover:bg-[#FFB849] disabled:opacity-50 transition-colors flex items-center gap-2 font-bold"
          >
            {loading ? (
              <><Loader2 className="animate-spin" size={20} /> searching...</>
            ) : (
              <><ShoeIcon size={20} className="transition-transform group-hover:scale-125 duration-200"/></>
            )}
          </button>
        </form>

        {/* Error Message */}
        {error && (
          <div className="mt-4 p-4 bg-[#E63946] text-white rounded-lg text-center">
            {error}
          </div>
        )}
      </div>

     {/* Track and Results Section */}
     {(recommendations.length > 0 || (data?.answer && !loading)) && (
        <div className="relative max-w-3xl mx-auto flex-1 min-h-[500px] mb-24">
          {/* Track Container */}
          <div className="absolute -inset-20 -rotate-6">
            {/* Main Track Outline */}
            <div className="absolute inset-0 rounded-[200px] overflow-hidden" />
            
            {/* Lane Lines - now in orange with decreasing opacity */}
            {[...Array(6)].map((_, i) => (
              <div
                key={i}
                className="absolute border-[3px] rounded-[200px]"
                style={{
                  top: `${8 + (i * 12)}px`,
                  right: `${8 + (i * 12)}px`,
                  bottom: `${8 + (i * 12)}px`,
                  left: `${8 + (i * 12)}px`,
                  borderColor: `rgba(176, 51, 17, ${0.7 - i * 0.1})`,
                }}
              />
            ))}

          </div>
          
          {/* Results Container - adjusted to fit oval */}
          <div className="relative mx-12 bg-[#1F2132]/90 backdrop-blur-sm rounded-[60px] p-8 shadow-2xl">
            {/* Rest of the content remains the same */}
            {/* No recommendations message */}
            {!loading && recommendations.length === 0 && data?.answer && (
              <div className="min-h-[400px] text-[#E4D9FF] flex items-center justify-center text-center text-lg p-8">
                {data.answer}
              </div>
            )}

            {/* Recommendations */}
            {recommendations.length > 0 && (
              <div className="space-y-8">
                {/* Recommendations Cards */}
                <div className="grid gap-6">
                  {recommendations.map((rec, idx) => (
                    <div 
                      key={idx} 
                      className="bg-[#2D3047] p-6 rounded-2xl border-2 border-[#FF9F1C]/20 hover:border-[#FF9F1C]/40 transition-colors"
                    >
                      <h3 className="text-[#FF9F1C] text-xl font-bold mb-3">
                        {rec.model}
                      </h3>
                      <p className="text-[#E4D9FF] leading-relaxed">
                        {rec.description}
                      </p>
                    </div>
                  ))}
                </div>

                {/* Sources Section */}
                {data?.sources && data.sources.length > 0 && (
                  <div className="pt-8 border-t-2 border-[#FF9F1C]/20">
                    <h3 className="text-[#FF9F1C] font-bold mb-4">you might find these videos interesting:</h3>
                    <ul className="space-y-3">
                      {data.sources.map((source, idx) => (
                        <li key={idx} className="flex items-start gap-2 group">
                          <ExternalLink size={16} className="mt-1 flex-shrink-0 text-[#FF9F1C]" />
                          <a
                            href={`https://youtube.com/watch?v=${source.video_id}`}
                            target="_blank"
                            rel="noopener noreferrer"
                            className="text-sm text-[#E4D9FF] group-hover:text-[#FF9F1C] transition-colors"
                          >
                            {source.title.toLowerCase()}
                          </a>
                        </li>
                      ))}
                    </ul>
                  </div>
                )}
              </div>
            )}
          </div>
        </div>
      )}
    </main>
  );
}

================
File: src/lib/get_python_path.ts
================
import { resolve } from 'path';
import { existsSync } from 'fs';

export function getPythonPath(): string {
//   const isDev = process.env.NODE_ENV === 'development';
  const rootDir = process.cwd();

  // Check for virtual environment
  const venvPython = process.platform === 'win32'
    ? resolve(rootDir, '.venv', 'Scripts', 'python.exe')
    : resolve(rootDir, '.venv', 'bin', 'python');

  if (existsSync(venvPython)) {
    return venvPython;
  }

  throw new Error('Virtual environment Python not found. Please run: uv venv && source .venv/bin/activate && uv pip install -r requirements.txt');
}

================
File: src/lib/main.py
================
import sys
import json
from shoe_advisor import ShoeAdvisor

def main():
    if len(sys.argv) < 2:
        print(json.dumps({
            "error": "No question provided"
        }))
        sys.exit(1)

    question = sys.argv[1]
    advisor = ShoeAdvisor()
    response = advisor.get_response(question)
    
    print(json.dumps(response))

if __name__ == "__main__":
    main()

================
File: src/lib/process_transcripts.py
================
from pathlib import Path
import json
import re
from typing import List, Dict
from dataclasses import dataclass

@dataclass
class TextChunk:
    text: str
    metadata: Dict
    
class TranscriptChunker:
    def __init__(self, chunk_size: int = 1000, overlap: int = 100):
        self.chunk_size = chunk_size
        self.overlap = overlap
    
    def clean_text(self, text: str) -> str:
        """Remove unnecessary whitespace and normalize text"""
        # Remove multiple newlines and spaces
        text = re.sub(r'\n+', ' ', text)
        text = re.sub(r'\s+', ' ', text)
        return text.strip()
    
    def split_into_chunks(self, text: str, title: str, video_id: str) -> List[TextChunk]:
        """Split text into overlapping chunks while trying to maintain sentence boundaries"""
        text = self.clean_text(text)
        chunks = []
        
        # Split into sentences (crude but functional for now)
        sentences = re.split(r'(?<=[.!?])\s+', text)
        
        current_chunk = []
        current_length = 0
        
        for sentence in sentences:
            sentence_length = len(sentence)
            
            if current_length + sentence_length > self.chunk_size and current_chunk:
                # Create chunk with metadata
                chunk_text = ' '.join(current_chunk)
                chunks.append(TextChunk(
                    text=chunk_text,
                    metadata={
                        'title': title,
                        'video_id': video_id,
                        'length': len(chunk_text),
                        'chunk_index': len(chunks)
                    }
                ))
                
                # Keep some sentences for overlap
                overlap_start = max(0, len(current_chunk) - self.overlap)
                current_chunk = current_chunk[overlap_start:]
                current_length = sum(len(s) for s in current_chunk)
            
            current_chunk.append(sentence)
            current_length += sentence_length
        
        # Don't forget the last chunk
        if current_chunk:
            chunk_text = ' '.join(current_chunk)
            chunks.append(TextChunk(
                text=chunk_text,
                metadata={
                    'title': title,
                    'video_id': video_id,
                    'length': len(chunk_text),
                    'chunk_index': len(chunks)
                }
            ))
        
        return chunks

def process_transcripts():
    chunker = TranscriptChunker()
    all_chunks = []
    data_dir = Path('data')
    
    # Process each channel directory
    for channel_dir in data_dir.iterdir():
        if not channel_dir.is_dir():
            continue
        
        json_path = channel_dir / 'processed_videos.json'
        if not json_path.exists():
            continue
        
        with open(json_path, 'r', encoding='utf-8') as f:
            videos = json.load(f)
        
        # Process each video
        for video in videos:
            if 'transcript' not in video or 'text' not in video['transcript']:
                continue
                
            chunks = chunker.split_into_chunks(
                video['transcript']['text'],
                video['title'],
                video['video_id']
            )
            all_chunks.extend(chunks)
    
    # Save chunks (for now, we'll improve storage later)
    chunks_dir = Path('processed_chunks')
    chunks_dir.mkdir(exist_ok=True)
    
    for i, chunk in enumerate(all_chunks):
        chunk_file = chunks_dir / f'chunk_{i:04d}.json'
        with open(chunk_file, 'w', encoding='utf-8') as f:
            json.dump({
                'text': chunk.text,
                'metadata': chunk.metadata
            }, f, indent=2)

if __name__ == "__main__":
    process_transcripts()

================
File: src/lib/query_cache.py
================
from pathlib import Path
import hashlib
import time
import pickle
import logging

class QueryCache:
    def __init__(self, cache_dir: str = 'query_cache', ttl_days: int = 30):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        self.ttl_seconds = ttl_days * 24 * 60 * 60
        logging.debug(f"Cache initialized at {self.cache_dir}")
        
    def _get_cache_key(self, query: str) -> str:
        """Create deterministic cache key from query"""
        return hashlib.md5(query.lower().strip().encode()).hexdigest()
    
    def _is_valid(self, timestamp: float) -> bool:
        """Check if cached item is still valid"""
        return (time.time() - timestamp) < self.ttl_seconds
    
    def get(self, query: str) -> dict:
        """Get cached response if it exists and is valid"""
        cache_key = self._get_cache_key(query)
        cache_file = self.cache_dir / f"{cache_key}.pkl"
        
        logging.debug(f"Looking for cache file: {cache_file}")
        
        if cache_file.exists():
            with open(cache_file, 'rb') as f:
                cached_data = pickle.load(f)
                if self._is_valid(cached_data['timestamp']):
                    logging.debug("Cache hit!")
                    return cached_data['response']
                else:
                    logging.debug("Cache expired")
                    cache_file.unlink()  # Remove expired cache
        logging.debug("Cache miss")
        return None
    
    def set(self, query: str, response: dict):
        """Cache a response"""
        cache_key = self._get_cache_key(query)
        cache_file = self.cache_dir / f"{cache_key}.pkl"
        
        cache_data = {
            'timestamp': time.time(),
            'response': response
        }
        
        with open(cache_file, 'wb') as f:
            pickle.dump(cache_data, f)
        logging.debug(f"Cached response at {cache_file}")

================
File: src/lib/shoe_advisor.py
================
import sys
import json
import logging
from pathlib import Path
from vector_store import ShoeKnowledgeBase
from openai import OpenAI
import os
from typing import List, Dict
from dotenv import load_dotenv
from query_cache import QueryCache

# Load environment variables from .env file
load_dotenv()

# Set up logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('debug.log'),
        logging.StreamHandler(sys.stderr)
    ]
)

class ShoeAdvisor:
    def __init__(self, kb_directory: str = 'shoe_knowledge'):
        """Initialize advisor with knowledge base, OpenAI client, and cache"""
        self.client = OpenAI()  # This will use OPENAI_API_KEY from environment
        self.knowledge_base = ShoeKnowledgeBase()
        self.knowledge_base.load(kb_directory)
        self.cache = QueryCache()  # Initialize the cache
        
        self.SYSTEM_PROMPT = """You are a knowledgeable running shoe expert. 
Use the provided context to suggest similar running shoes. Your answer should contain just a few running shoes and one brief bullet point with the reasoning for the suggestion.

Format your response exactly like this example:
- **Nike Pegasus 41**
  - A solid entry-level model with good stability and comfort.
- **Nike Invincible 3**
  - Maximum cushioning and bounce for recovery runs.

Use 2-4 shoe recommendations, each with:
- Model name in bold between two newlines
- Description on a new indented line starting with a bullet point
- Keep descriptions concise (one sentence)
- Don't add any concluding text after recommendations

If you can't find enough information in the context, say so."""

    def format_context(self, chunks: List[Dict]) -> str:
        """Format chunks into context string"""
        context_parts = []
        for chunk in chunks:
            context_parts.append(f"From video '{chunk['chunk']['metadata']['title']}':")
            context_parts.append(chunk['chunk']['text'])
        return "\n\n".join(context_parts)

    def get_response(self, question: str) -> Dict:
        """Get response for user query, using cache when possible"""
        logging.debug(f"Getting response for question: {question}")
        
        try:
            # Check cache first
            cached_response = self.cache.get(question)
            if cached_response:
                logging.debug("Using cached response")
                return cached_response
            
            # If not in cache, get new response
            relevant_chunks = self.knowledge_base.search(question, k=3)
            logging.debug(f"Found {len(relevant_chunks)} relevant chunks")
            
            if not relevant_chunks:
                response = {
                    "answer": "I couldn't find any relevant information to answer your question.",
                    "sources": []
                }
                self.cache.set(question, response)  # Cache the no-results response
                return response
            
            # Format context
            context = self.format_context(relevant_chunks)
            logging.debug("Context formatted successfully")
            
            # Create messages for GPT
            messages = [
                {"role": "system", "content": self.SYSTEM_PROMPT},
                {"role": "user", "content": f"""Context:
{context}

User Question: {question}

Please provide an answer based on the context above."""}
            ]
            
            # Get GPT response
            logging.debug("Calling OpenAI API")
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                temperature=0.7
            )
            
            answer = response.choices[0].message.content
            logging.debug("Received response from OpenAI")
            
            # Format final response with sources
            final_response = {
                "answer": answer,
                "sources": [
                    {
                        "title": chunk['chunk']['metadata']['title'],
                        "video_id": chunk['chunk']['metadata']['video_id']
                    }
                    for chunk in relevant_chunks
                ]
            }
            
            # Cache the response before returning
            self.cache.set(question, final_response)
            logging.debug("Response cached")
            
            return final_response
            
        except Exception as e:
            error_msg = f"Error in get_response: {str(e)}"
            logging.error(error_msg)
            response = {
                "error": "Failed to process request",
                "details": str(e)
            }
            # Don't cache error responses
            return response

def main():
    logging.debug("Script started")
    
    if len(sys.argv) < 2:
        error_response = {
            "error": "No question provided"
        }
        logging.error(error_response)
        print(json.dumps(error_response))
        sys.exit(1)

    try:
        question = sys.argv[1]
        logging.debug(f"Received question: {question}")
        
        # Initialize advisor
        logging.debug("Initializing ShoeAdvisor")
        advisor = ShoeAdvisor()
        
        # Get and return response
        response = advisor.get_response(question)
        logging.debug(f"Got response: {response}")
        
        # Print the JSON response
        json_response = json.dumps(response)
        print(json_response)
        
        logging.debug("Script completed successfully")
        
    except Exception as e:
        error_response = {
            "error": "Failed to process request",
            "details": str(e)
        }
        logging.error(f"Error in main: {str(e)}")
        print(json.dumps(error_response))
        sys.exit(1)

if __name__ == "__main__":
    main()

================
File: src/lib/vector_store.py
================
import json
from pathlib import Path
import numpy as np
from openai import OpenAI
import faiss
import pickle
from typing import List, Dict
import time

import os
from dotenv import load_dotenv

load_dotenv()

class ShoeKnowledgeBase:
    def __init__(self):
        # Initialize OpenAI client
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        # Initialize FAISS index
        # 1536 is the dimensionality of OpenAI's text-embedding-3-small embeddings
        self.index = faiss.IndexFlatL2(1536)
        
        # Store mapping of FAISS index positions to chunk data
        self.chunk_data: List[Dict] = []
    
    def get_embedding(self, text: str) -> np.ndarray:
        """Get embedding vector for a text using OpenAI's API"""
        try:
            # Add a small delay to respect rate limits
            time.sleep(0.1)
            
            response = self.client.embeddings.create(
                input=text,
                model="text-embedding-3-small"
            )
            # Convert embedding to numpy array
            return np.array(response.data[0].embedding, dtype=np.float32)
        except Exception as e:
            print(f"Error getting embedding: {e}")
            return None

    def add_chunk(self, text: str, metadata: Dict):
        """Add a single chunk to the knowledge base"""
        embedding = self.get_embedding(text)
        if embedding is not None:
            # Add to FAISS index
            self.index.add(embedding.reshape(1, -1))
            # Store chunk data at same position
            self.chunk_data.append({
                'text': text,
                'metadata': metadata
            })
    
    def process_chunks_directory(self, chunks_dir: str):
        """Process all chunks in directory"""
        chunks_path = Path(chunks_dir)
        print(f"Processing chunks from {chunks_path}")
        
        for chunk_file in chunks_path.glob('chunk_*.json'):
            with open(chunk_file, 'r', encoding='utf-8') as f:
                chunk = json.load(f)
                print(f"Processing {chunk_file.name}")
                self.add_chunk(chunk['text'], chunk['metadata'])
    
    def save(self, directory: str):
        """Save the knowledge base to disk"""
        save_dir = Path(directory)
        save_dir.mkdir(exist_ok=True)
        
        # Save FAISS index
        faiss.write_index(self.index, str(save_dir / 'shoe_knowledge.index'))
        
        # Save chunk data
        with open(save_dir / 'chunk_data.pkl', 'wb') as f:
            pickle.dump(self.chunk_data, f)
    
    def load(self, directory: str):
        """Load the knowledge base from disk"""
        load_dir = Path(directory)
        
        # Load FAISS index
        self.index = faiss.read_index(str(load_dir / 'shoe_knowledge.index'))
        
        # Load chunk data
        with open(load_dir / 'chunk_data.pkl', 'rb') as f:
            self.chunk_data = pickle.load(f)
    
    def search(self, query: str, k: int = 3) -> List[Dict]:
        """Search for most relevant chunks"""
        # Get query embedding
        query_embedding = self.get_embedding(query)
        if query_embedding is None:
            return []
        
        # Search in FAISS
        distances, indices = self.index.search(query_embedding.reshape(1, -1), k)
        
        # Return relevant chunks
        results = []
        for i, idx in enumerate(indices[0]):
            results.append({
                'chunk': self.chunk_data[idx],
                'distance': float(distances[0][i])
            })
        
        return results

def main():
    # Initialize knowledge base
    kb = ShoeKnowledgeBase()
    
    # Process all chunks
    kb.process_chunks_directory('processed_chunks')
    
    # Save the knowledge base
    kb.save('shoe_knowledge')
    
    # Example search
    print("\nTesting search...")
    results = kb.search("What are good shoes for marathon racing?")
    for result in results:
        print("\nRelevant chunk:")
        print(f"Title: {result['chunk']['metadata']['title']}")
        print(f"Text: {result['chunk']['text'][:200]}...")
        print(f"Distance: {result['distance']}")

if __name__ == "__main__":
    main()

================
File: src/lib/youtube_transcript_getter.py
================
from typing import List, Dict
from datetime import datetime, timedelta
from googleapiclient.discovery import build
from youtube_transcript_api import YouTubeTranscriptApi
from youtube_transcript_api.formatters import TextFormatter
import json
import logging
from pathlib import Path

import os
from dotenv import load_dotenv

load_dotenv()

class YouTubeCaptionCollector:
    def __init__(self, api_key: str):
        self.youtube = build('youtube', 'v3', developerKey=api_key)
        self.formatter = TextFormatter()
        self.setup_logging()
        
    def setup_logging(self):
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('youtube_collector.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)

    def get_channel_videos(self, channel_id: str, published_after: datetime, max_results: int = 50) -> List[Dict]:
        try:
            channel_response = self.youtube.channels().list(
                part='contentDetails',
                id=channel_id
            ).execute()
            
            if not channel_response.get('items'):
                self.logger.error(f"No channel found for ID {channel_id}")
                return []
                
            uploads_playlist_id = channel_response['items'][0]['contentDetails']['relatedPlaylists']['uploads']
            
            videos = []
            next_page_token = None
            
            while True:
                playlist_response = self.youtube.playlistItems().list(
                    part='snippet',
                    playlistId=uploads_playlist_id,
                    maxResults=50,
                    pageToken=next_page_token
                ).execute()
                
                for item in playlist_response['items']:
                    video_date = datetime.strptime(
                        item['snippet']['publishedAt'],
                        '%Y-%m-%dT%H:%M:%SZ'
                    )
                    
                    if video_date < published_after:
                        return videos
                        
                    videos.append({
                        'video_id': item['snippet']['resourceId']['videoId'],
                        'title': item['snippet']['title'],
                        'description': item['snippet']['description'],
                        'published_at': item['snippet']['publishedAt']
                    })
                    
                    if len(videos) >= max_results:
                        return videos
                
                next_page_token = playlist_response.get('nextPageToken')
                if not next_page_token:
                    break
                    
            return videos
            
        except Exception as e:
            self.logger.error(f"Error fetching videos for channel {channel_id}: {str(e)}")
            return []

    def get_video_captions(self, video_id: str) -> Dict:
        try:
            transcript = YouTubeTranscriptApi.get_transcript(video_id)
            formatted_transcript = self.formatter.format_transcript(transcript)
            
            return {
                'text': formatted_transcript,
                'segments': transcript
            }
            
        except Exception as e:
            self.logger.error(f"Error fetching captions for video {video_id}: {str(e)}")
            return None

    def process_channel(self, channel_id: str, output_dir: str, months_back: int = 24) -> List[Dict]:
        transcript_dir = Path(output_dir) / 'transcripts'
        transcript_dir.mkdir(parents=True, exist_ok=True)
        
        published_after = datetime.now() - timedelta(days=30.44 * months_back)
        
        videos = self.get_channel_videos(channel_id, published_after)
        self.logger.info(f"Found {len(videos)} videos for channel {channel_id}")
        
        processed_videos = []
        
        for video in videos:
            video_id = video['video_id']
            transcript_path = transcript_dir / f"{video_id}.json"
            
            if transcript_path.exists():
                with open(transcript_path, 'r') as f:
                    transcript = json.load(f)
            else:
                transcript = self.get_video_captions(video_id)
                if transcript:
                    with open(transcript_path, 'w') as f:
                        json.dump(transcript, f, indent=2)
            
            if transcript:
                processed_videos.append({
                    **video,
                    'transcript': transcript
                })
            
        return processed_videos

def main():
    channels = [
        # {
        #     'name': 'Kofuzi',
        #     'id': 'UCe43pe3w4L6w3tNMRkWiJBA'
        # },
        # {
        #     'name':'Seth James Demoor',
        #     'id':'UCeSHo5kTvzoik4STh7MuMCA'
        # },
        {
            'name':'Ben Parkes',
            'id':'UCZPqG0yh_xPm2AyLjffbDvw'
        },
        {
            'name':'The Run Testers',
            'id':'UCOBM9FasII4dKbyE_HKkbjw'
        },
        {
            'name':'Believe in the Run',
            'id':'UC2-2J_y_jpOYz8Rld5C6C5w'
        },
        
    ]
    
    collector = YouTubeCaptionCollector(os.getenv("YOUTUBE_API_KEY"))
    
    for channel in channels:
        print(f"Processing channel {channel['name']}.\n")
        output_dir = f"data/{channel['name'].lower().replace(' ', '_')}"
        videos = collector.process_channel(channel['id'], output_dir)
        
        with open(f"{output_dir}/processed_videos.json", 'w') as f:
            json.dump(videos, f, indent=2)

if __name__ == "__main__":
    main()

================
File: .gitignore
================
# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.

# dependencies
/node_modules
/.pnp
.pnp.*
.yarn/*
!.yarn/patches
!.yarn/plugins
!.yarn/releases
!.yarn/versions

# testing
/coverage

# next.js
/.next/
/out/

# production
/build

# misc
.DS_Store
*.pem

# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*
.pnpm-debug.log*

# env files (can opt-in for committing if needed)
.env*

# vercel
.vercel

# typescript
*.tsbuildinfo
next-env.d.ts

.venv

================
File: .python-version
================
3.13

================
File: eslint.config.mjs
================
import { dirname } from "path";
import { fileURLToPath } from "url";
import { FlatCompat } from "@eslint/eslintrc";

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

const compat = new FlatCompat({
  baseDirectory: __dirname,
});

const eslintConfig = [
  ...compat.extends("next/core-web-vitals", "next/typescript"),
];

export default eslintConfig;

================
File: hello.py
================
def main():
    print("Hello from shoe-advisor!")


if __name__ == "__main__":
    main()

================
File: next.config.ts
================
import type { NextConfig } from 'next'

const nextConfig: NextConfig = {
  webpack: (config) => {
    config.externals = [...(config.externals || []), {
      'shelljs': 'commonjs shelljs',
    }]
    return config
  },
}

export default nextConfig

================
File: package.json
================
{
  "name": "shoe-advisor",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev --turbopack",
    "build": "next build",
    "start": "next start",
    "lint": "next lint"
  },
  "dependencies": {
    "@types/shelljs": "^0.8.15",
    "lucide-react": "^0.469.0",
    "next": "15.1.3",
    "react": "^19.0.0",
    "react-dom": "^19.0.0",
    "shelljs": "^0.8.5"
  },
  "devDependencies": {
    "@eslint/eslintrc": "^3",
    "@types/node": "^20",
    "@types/react": "^19",
    "@types/react-dom": "^19",
    "eslint": "^9",
    "eslint-config-next": "15.1.3",
    "postcss": "^8",
    "tailwindcss": "^3.4.1",
    "typescript": "^5"
  }
}

================
File: postcss.config.mjs
================
/** @type {import('postcss-load-config').Config} */
const config = {
  plugins: {
    tailwindcss: {},
  },
};

export default config;

================
File: pyproject.toml
================
[project]
name = "shoe-advisor"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.13"
dependencies = [
    "faiss-cpu>=1.9.0.post1",
    "numpy>=2.2.1",
    "openai>=1.59.4",
    "python-dotenv>=1.0.1",
]

================
File: README.md
================
This is a [Next.js](https://nextjs.org) project bootstrapped with [`create-next-app`](https://nextjs.org/docs/app/api-reference/cli/create-next-app).

## Getting Started

First, run the development server:

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
# or
bun dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

You can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.

This project uses [`next/font`](https://nextjs.org/docs/app/building-your-application/optimizing/fonts) to automatically optimize and load [Geist](https://vercel.com/font), a new font family for Vercel.

## Learn More

To learn more about Next.js, take a look at the following resources:

- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.
- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.

You can check out [the Next.js GitHub repository](https://github.com/vercel/next.js) - your feedback and contributions are welcome!

## Deploy on Vercel

The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.

Check out our [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.

================
File: tailwind.config.ts
================
import type { Config } from "tailwindcss";

export default {
  content: [
    "./src/pages/**/*.{js,ts,jsx,tsx,mdx}",
    "./src/components/**/*.{js,ts,jsx,tsx,mdx}",
    "./src/app/**/*.{js,ts,jsx,tsx,mdx}",
  ],
  theme: {
    extend: {
      colors: {
        background: "var(--background)",
        foreground: "var(--foreground)",
      },
    },
  },
  plugins: [],
} satisfies Config;

================
File: tsconfig.json
================
{
  "compilerOptions": {
    "target": "es5",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
  "exclude": ["node_modules"]
}

================
File: uv.lock
================
version = 1
requires-python = ">=3.13"

[[package]]
name = "annotated-types"
version = "0.7.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/ee/67/531ea369ba64dcff5ec9c3402f9f51bf748cec26dde048a2f973a4eea7f5/annotated_types-0.7.0.tar.gz", hash = "sha256:aff07c09a53a08bc8cfccb9c85b05f1aa9a2a6f23728d790723543408344ce89", size = 16081 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl", hash = "sha256:1f02e8b43a8fbbc3f3e0d4f0f4bfc8131bcb4eebe8849b8e5c773f3a1c582a53", size = 13643 },
]

[[package]]
name = "anyio"
version = "4.8.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "idna" },
    { name = "sniffio" },
]
sdist = { url = "https://files.pythonhosted.org/packages/a3/73/199a98fc2dae33535d6b8e8e6ec01f8c1d76c9adb096c6b7d64823038cde/anyio-4.8.0.tar.gz", hash = "sha256:1d9fe889df5212298c0c0723fa20479d1b94883a2df44bd3897aa91083316f7a", size = 181126 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/46/eb/e7f063ad1fec6b3178a3cd82d1a3c4de82cccf283fc42746168188e1cdd5/anyio-4.8.0-py3-none-any.whl", hash = "sha256:b5011f270ab5eb0abf13385f851315585cc37ef330dd88e27ec3d34d651fd47a", size = 96041 },
]

[[package]]
name = "certifi"
version = "2024.12.14"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/0f/bd/1d41ee578ce09523c81a15426705dd20969f5abf006d1afe8aeff0dd776a/certifi-2024.12.14.tar.gz", hash = "sha256:b650d30f370c2b724812bee08008be0c4163b163ddaec3f2546c1caf65f191db", size = 166010 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/a5/32/8f6669fc4798494966bf446c8c4a162e0b5d893dff088afddf76414f70e1/certifi-2024.12.14-py3-none-any.whl", hash = "sha256:1275f7a45be9464efc1173084eaa30f866fe2e47d389406136d332ed4967ec56", size = 164927 },
]

[[package]]
name = "colorama"
version = "0.4.6"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/d8/53/6f443c9a4a8358a93a6792e2acffb9d9d5cb0a5cfd8802644b7b1c9a02e4/colorama-0.4.6.tar.gz", hash = "sha256:08695f5cb7ed6e0531a20572697297273c47b8cae5a63ffc6d6ed5c201be6e44", size = 27697 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d1/d6/3965ed04c63042e047cb6a3e6ed1a63a35087b6a609aa3a15ed8ac56c221/colorama-0.4.6-py2.py3-none-any.whl", hash = "sha256:4f1d9991f5acc0ca119f9d443620b77f9d6b33703e51011c16baf57afb285fc6", size = 25335 },
]

[[package]]
name = "distro"
version = "1.9.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/fc/f8/98eea607f65de6527f8a2e8885fc8015d3e6f5775df186e443e0964a11c3/distro-1.9.0.tar.gz", hash = "sha256:2fa77c6fd8940f116ee1d6b94a2f90b13b5ea8d019b98bc8bafdcabcdd9bdbed", size = 60722 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl", hash = "sha256:7bffd925d65168f85027d8da9af6bddab658135b840670a223589bc0c8ef02b2", size = 20277 },
]

[[package]]
name = "faiss-cpu"
version = "1.9.0.post1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "numpy" },
    { name = "packaging" },
]
sdist = { url = "https://files.pythonhosted.org/packages/03/1f/d0ac8e9d6fc7fc37dc682878f56edb23000c31b74f48cafe9f1a6efaae20/faiss_cpu-1.9.0.post1.tar.gz", hash = "sha256:920725d485aab05dd87d34ef63257332441e9b53d382069f034996465827143a", size = 67799 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d4/58/bb51abeb207ba008b066225dc0c185f51bb93f5588fd2b239550bec6a027/faiss_cpu-1.9.0.post1-cp313-cp313-macosx_10_14_x86_64.whl", hash = "sha256:10e38642c5f147642c4aa8a6c1704fb1900b2b8dd5f33b49a45fa5a67df4837d", size = 7700462 },
    { url = "https://files.pythonhosted.org/packages/b2/7d/a9203f5b71405308111d2e172b98e5e243059397a8731930310d9471ffae/faiss_cpu-1.9.0.post1-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:ec25338fc06fa8aa6ef5c7a2ba9f1aa03f64f9b38ba82402a6495cc981426571", size = 3227854 },
    { url = "https://files.pythonhosted.org/packages/cd/c7/c7be2eb63c4c1a26380c487070d78ac35e6a409c427c22a38536961188ef/faiss_cpu-1.9.0.post1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:2951be3d2713a128e7f625a4b508419238b6c09cce747a0de7708bdcf1b7e3d6", size = 3651917 },
    { url = "https://files.pythonhosted.org/packages/23/0a/2b93a3cae49bc0e7c1de362ca04f4daf9171fd2cf773c867086a8a5c71cf/faiss_cpu-1.9.0.post1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:a6467aafa148d39e6e9bc26c1d84e07f16cbf910297a90ec2e8597cf69772a82", size = 27471814 },
    { url = "https://files.pythonhosted.org/packages/6c/9b/b9565fe8ee40f665c4d6f926d67a2d00e01e1d2c3c2e873f268b87a9a083/faiss_cpu-1.9.0.post1-cp313-cp313-win_amd64.whl", hash = "sha256:87a224a01a4ad80e0f849b2b2b1fba8b197e5803416ea861faf1b0de255871ea", size = 13845706 },
]

[[package]]
name = "h11"
version = "0.14.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/f5/38/3af3d3633a34a3316095b39c8e8fb4853a28a536e55d347bd8d8e9a14b03/h11-0.14.0.tar.gz", hash = "sha256:8f19fbbe99e72420ff35c00b27a34cb9937e902a8b810e2c88300c6f0a3b699d", size = 100418 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl", hash = "sha256:e3fe4ac4b851c468cc8363d500db52c2ead036020723024a109d37346efaa761", size = 58259 },
]

[[package]]
name = "httpcore"
version = "1.0.7"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "certifi" },
    { name = "h11" },
]
sdist = { url = "https://files.pythonhosted.org/packages/6a/41/d7d0a89eb493922c37d343b607bc1b5da7f5be7e383740b4753ad8943e90/httpcore-1.0.7.tar.gz", hash = "sha256:8551cb62a169ec7162ac7be8d4817d561f60e08eaa485234898414bb5a8a0b4c", size = 85196 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/87/f5/72347bc88306acb359581ac4d52f23c0ef445b57157adedb9aee0cd689d2/httpcore-1.0.7-py3-none-any.whl", hash = "sha256:a3fff8f43dc260d5bd363d9f9cf1830fa3a458b332856f34282de498ed420edd", size = 78551 },
]

[[package]]
name = "httpx"
version = "0.28.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "anyio" },
    { name = "certifi" },
    { name = "httpcore" },
    { name = "idna" },
]
sdist = { url = "https://files.pythonhosted.org/packages/b1/df/48c586a5fe32a0f01324ee087459e112ebb7224f646c0b5023f5e79e9956/httpx-0.28.1.tar.gz", hash = "sha256:75e98c5f16b0f35b567856f597f06ff2270a374470a5c2392242528e3e3e42fc", size = 141406 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/2a/39/e50c7c3a983047577ee07d2a9e53faf5a69493943ec3f6a384bdc792deb2/httpx-0.28.1-py3-none-any.whl", hash = "sha256:d909fcccc110f8c7faf814ca82a9a4d816bc5a6dbfea25d6591d6985b8ba59ad", size = 73517 },
]

[[package]]
name = "idna"
version = "3.10"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/f1/70/7703c29685631f5a7590aa73f1f1d3fa9a380e654b86af429e0934a32f7d/idna-3.10.tar.gz", hash = "sha256:12f65c9b470abda6dc35cf8e63cc574b1c52b11df2c86030af0ac09b01b13ea9", size = 190490 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/76/c6/c88e154df9c4e1a2a66ccf0005a88dfb2650c1dffb6f5ce603dfbd452ce3/idna-3.10-py3-none-any.whl", hash = "sha256:946d195a0d259cbba61165e88e65941f16e9b36ea6ddb97f00452bae8b1287d3", size = 70442 },
]

[[package]]
name = "jiter"
version = "0.8.2"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/f8/70/90bc7bd3932e651486861df5c8ffea4ca7c77d28e8532ddefe2abc561a53/jiter-0.8.2.tar.gz", hash = "sha256:cd73d3e740666d0e639f678adb176fad25c1bcbdae88d8d7b857e1783bb4212d", size = 163007 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/6c/b0/bfa1f6f2c956b948802ef5a021281978bf53b7a6ca54bb126fd88a5d014e/jiter-0.8.2-cp313-cp313-macosx_10_12_x86_64.whl", hash = "sha256:ca1f08b8e43dc3bd0594c992fb1fd2f7ce87f7bf0d44358198d6da8034afdf84", size = 301190 },
    { url = "https://files.pythonhosted.org/packages/a4/8f/396ddb4e292b5ea57e45ade5dc48229556b9044bad29a3b4b2dddeaedd52/jiter-0.8.2-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:5672a86d55416ccd214c778efccf3266b84f87b89063b582167d803246354be4", size = 309334 },
    { url = "https://files.pythonhosted.org/packages/7f/68/805978f2f446fa6362ba0cc2e4489b945695940656edd844e110a61c98f8/jiter-0.8.2-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:58dc9bc9767a1101f4e5e22db1b652161a225874d66f0e5cb8e2c7d1c438b587", size = 333918 },
    { url = "https://files.pythonhosted.org/packages/b3/99/0f71f7be667c33403fa9706e5b50583ae5106d96fab997fa7e2f38ee8347/jiter-0.8.2-cp313-cp313-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:37b2998606d6dadbb5ccda959a33d6a5e853252d921fec1792fc902351bb4e2c", size = 356057 },
    { url = "https://files.pythonhosted.org/packages/8d/50/a82796e421a22b699ee4d2ce527e5bcb29471a2351cbdc931819d941a167/jiter-0.8.2-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:4ab9a87f3784eb0e098f84a32670cfe4a79cb6512fd8f42ae3d0709f06405d18", size = 379790 },
    { url = "https://files.pythonhosted.org/packages/3c/31/10fb012b00f6d83342ca9e2c9618869ab449f1aa78c8f1b2193a6b49647c/jiter-0.8.2-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:79aec8172b9e3c6d05fd4b219d5de1ac616bd8da934107325a6c0d0e866a21b6", size = 388285 },
    { url = "https://files.pythonhosted.org/packages/c8/81/f15ebf7de57be488aa22944bf4274962aca8092e4f7817f92ffa50d3ee46/jiter-0.8.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:711e408732d4e9a0208008e5892c2966b485c783cd2d9a681f3eb147cf36c7ef", size = 344764 },
    { url = "https://files.pythonhosted.org/packages/b3/e8/0cae550d72b48829ba653eb348cdc25f3f06f8a62363723702ec18e7be9c/jiter-0.8.2-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:653cf462db4e8c41995e33d865965e79641ef45369d8a11f54cd30888b7e6ff1", size = 376620 },
    { url = "https://files.pythonhosted.org/packages/b8/50/e5478ff9d82534a944c03b63bc217c5f37019d4a34d288db0f079b13c10b/jiter-0.8.2-cp313-cp313-musllinux_1_1_aarch64.whl", hash = "sha256:9c63eaef32b7bebac8ebebf4dabebdbc6769a09c127294db6babee38e9f405b9", size = 510402 },
    { url = "https://files.pythonhosted.org/packages/8e/1e/3de48bbebbc8f7025bd454cedc8c62378c0e32dd483dece5f4a814a5cb55/jiter-0.8.2-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:eb21aaa9a200d0a80dacc7a81038d2e476ffe473ffdd9c91eb745d623561de05", size = 503018 },
    { url = "https://files.pythonhosted.org/packages/d5/cd/d5a5501d72a11fe3e5fd65c78c884e5164eefe80077680533919be22d3a3/jiter-0.8.2-cp313-cp313-win32.whl", hash = "sha256:789361ed945d8d42850f919342a8665d2dc79e7e44ca1c97cc786966a21f627a", size = 203190 },
    { url = "https://files.pythonhosted.org/packages/51/bf/e5ca301245ba951447e3ad677a02a64a8845b185de2603dabd83e1e4b9c6/jiter-0.8.2-cp313-cp313-win_amd64.whl", hash = "sha256:ab7f43235d71e03b941c1630f4b6e3055d46b6cb8728a17663eaac9d8e83a865", size = 203551 },
    { url = "https://files.pythonhosted.org/packages/2f/3c/71a491952c37b87d127790dd7a0b1ebea0514c6b6ad30085b16bbe00aee6/jiter-0.8.2-cp313-cp313t-macosx_11_0_arm64.whl", hash = "sha256:b426f72cd77da3fec300ed3bc990895e2dd6b49e3bfe6c438592a3ba660e41ca", size = 308347 },
    { url = "https://files.pythonhosted.org/packages/a0/4c/c02408042e6a7605ec063daed138e07b982fdb98467deaaf1c90950cf2c6/jiter-0.8.2-cp313-cp313t-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:b2dd880785088ff2ad21ffee205e58a8c1ddabc63612444ae41e5e4b321b39c0", size = 342875 },
    { url = "https://files.pythonhosted.org/packages/91/61/c80ef80ed8a0a21158e289ef70dac01e351d929a1c30cb0f49be60772547/jiter-0.8.2-cp313-cp313t-win_amd64.whl", hash = "sha256:3ac9f578c46f22405ff7f8b1f5848fb753cc4b8377fbec8470a7dc3997ca7566", size = 202374 },
]

[[package]]
name = "numpy"
version = "2.2.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/f2/a5/fdbf6a7871703df6160b5cf3dd774074b086d278172285c52c2758b76305/numpy-2.2.1.tar.gz", hash = "sha256:45681fd7128c8ad1c379f0ca0776a8b0c6583d2f69889ddac01559dfe4390918", size = 20227662 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/20/d6/91a26e671c396e0c10e327b763485ee295f5a5a7a48c553f18417e5a0ed5/numpy-2.2.1-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:f1d09e520217618e76396377c81fba6f290d5f926f50c35f3a5f72b01a0da780", size = 20896464 },
    { url = "https://files.pythonhosted.org/packages/8c/40/5792ccccd91d45e87d9e00033abc4f6ca8a828467b193f711139ff1f1cd9/numpy-2.2.1-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:3ecc47cd7f6ea0336042be87d9e7da378e5c7e9b3c8ad0f7c966f714fc10d821", size = 14111350 },
    { url = "https://files.pythonhosted.org/packages/c0/2a/fb0a27f846cb857cef0c4c92bef89f133a3a1abb4e16bba1c4dace2e9b49/numpy-2.2.1-cp313-cp313-macosx_14_0_arm64.whl", hash = "sha256:f419290bc8968a46c4933158c91a0012b7a99bb2e465d5ef5293879742f8797e", size = 5111629 },
    { url = "https://files.pythonhosted.org/packages/eb/e5/8e81bb9d84db88b047baf4e8b681a3e48d6390bc4d4e4453eca428ecbb49/numpy-2.2.1-cp313-cp313-macosx_14_0_x86_64.whl", hash = "sha256:5b6c390bfaef8c45a260554888966618328d30e72173697e5cabe6b285fb2348", size = 6645865 },
    { url = "https://files.pythonhosted.org/packages/7a/1a/a90ceb191dd2f9e2897c69dde93ccc2d57dd21ce2acbd7b0333e8eea4e8d/numpy-2.2.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:526fc406ab991a340744aad7e25251dd47a6720a685fa3331e5c59fef5282a59", size = 14043508 },
    { url = "https://files.pythonhosted.org/packages/f1/5a/e572284c86a59dec0871a49cd4e5351e20b9c751399d5f1d79628c0542cb/numpy-2.2.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:f74e6fdeb9a265624ec3a3918430205dff1df7e95a230779746a6af78bc615af", size = 16094100 },
    { url = "https://files.pythonhosted.org/packages/0c/2c/a79d24f364788386d85899dd280a94f30b0950be4b4a545f4fa4ed1d4ca7/numpy-2.2.1-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:53c09385ff0b72ba79d8715683c1168c12e0b6e84fb0372e97553d1ea91efe51", size = 15239691 },
    { url = "https://files.pythonhosted.org/packages/cf/79/1e20fd1c9ce5a932111f964b544facc5bb9bde7865f5b42f00b4a6a9192b/numpy-2.2.1-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:f3eac17d9ec51be534685ba877b6ab5edc3ab7ec95c8f163e5d7b39859524716", size = 17856571 },
    { url = "https://files.pythonhosted.org/packages/be/5b/cc155e107f75d694f562bdc84a26cc930569f3dfdfbccb3420b626065777/numpy-2.2.1-cp313-cp313-win32.whl", hash = "sha256:9ad014faa93dbb52c80d8f4d3dcf855865c876c9660cb9bd7553843dd03a4b1e", size = 6270841 },
    { url = "https://files.pythonhosted.org/packages/44/be/0e5cd009d2162e4138d79a5afb3b5d2341f0fe4777ab6e675aa3d4a42e21/numpy-2.2.1-cp313-cp313-win_amd64.whl", hash = "sha256:164a829b6aacf79ca47ba4814b130c4020b202522a93d7bff2202bfb33b61c60", size = 12606618 },
    { url = "https://files.pythonhosted.org/packages/a8/87/04ddf02dd86fb17c7485a5f87b605c4437966d53de1e3745d450343a6f56/numpy-2.2.1-cp313-cp313t-macosx_10_13_x86_64.whl", hash = "sha256:4dfda918a13cc4f81e9118dea249e192ab167a0bb1966272d5503e39234d694e", size = 20921004 },
    { url = "https://files.pythonhosted.org/packages/6e/3e/d0e9e32ab14005425d180ef950badf31b862f3839c5b927796648b11f88a/numpy-2.2.1-cp313-cp313t-macosx_11_0_arm64.whl", hash = "sha256:733585f9f4b62e9b3528dd1070ec4f52b8acf64215b60a845fa13ebd73cd0712", size = 14119910 },
    { url = "https://files.pythonhosted.org/packages/b5/5b/aa2d1905b04a8fb681e08742bb79a7bddfc160c7ce8e1ff6d5c821be0236/numpy-2.2.1-cp313-cp313t-macosx_14_0_arm64.whl", hash = "sha256:89b16a18e7bba224ce5114db863e7029803c179979e1af6ad6a6b11f70545008", size = 5153612 },
    { url = "https://files.pythonhosted.org/packages/ce/35/6831808028df0648d9b43c5df7e1051129aa0d562525bacb70019c5f5030/numpy-2.2.1-cp313-cp313t-macosx_14_0_x86_64.whl", hash = "sha256:676f4eebf6b2d430300f1f4f4c2461685f8269f94c89698d832cdf9277f30b84", size = 6668401 },
    { url = "https://files.pythonhosted.org/packages/b1/38/10ef509ad63a5946cc042f98d838daebfe7eaf45b9daaf13df2086b15ff9/numpy-2.2.1-cp313-cp313t-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:27f5cdf9f493b35f7e41e8368e7d7b4bbafaf9660cba53fb21d2cd174ec09631", size = 14014198 },
    { url = "https://files.pythonhosted.org/packages/df/f8/c80968ae01df23e249ee0a4487fae55a4c0fe2f838dfe9cc907aa8aea0fa/numpy-2.2.1-cp313-cp313t-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:c1ad395cf254c4fbb5b2132fee391f361a6e8c1adbd28f2cd8e79308a615fe9d", size = 16076211 },
    { url = "https://files.pythonhosted.org/packages/09/69/05c169376016a0b614b432967ac46ff14269eaffab80040ec03ae1ae8e2c/numpy-2.2.1-cp313-cp313t-musllinux_1_2_aarch64.whl", hash = "sha256:08ef779aed40dbc52729d6ffe7dd51df85796a702afbf68a4f4e41fafdc8bda5", size = 15220266 },
    { url = "https://files.pythonhosted.org/packages/f1/ff/94a4ce67ea909f41cf7ea712aebbe832dc67decad22944a1020bb398a5ee/numpy-2.2.1-cp313-cp313t-musllinux_1_2_x86_64.whl", hash = "sha256:26c9c4382b19fcfbbed3238a14abf7ff223890ea1936b8890f058e7ba35e8d71", size = 17852844 },
    { url = "https://files.pythonhosted.org/packages/46/72/8a5dbce4020dfc595592333ef2fbb0a187d084ca243b67766d29d03e0096/numpy-2.2.1-cp313-cp313t-win32.whl", hash = "sha256:93cf4e045bae74c90ca833cba583c14b62cb4ba2cba0abd2b141ab52548247e2", size = 6326007 },
    { url = "https://files.pythonhosted.org/packages/7b/9c/4fce9cf39dde2562584e4cfd351a0140240f82c0e3569ce25a250f47037d/numpy-2.2.1-cp313-cp313t-win_amd64.whl", hash = "sha256:bff7d8ec20f5f42607599f9994770fa65d76edca264a87b5e4ea5629bce12268", size = 12693107 },
]

[[package]]
name = "openai"
version = "1.59.4"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "anyio" },
    { name = "distro" },
    { name = "httpx" },
    { name = "jiter" },
    { name = "pydantic" },
    { name = "sniffio" },
    { name = "tqdm" },
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/38/db/0e1376bdee3de8c16d91647d47dc47a26d2d6036931c76844e7d3e3fb989/openai-1.59.4.tar.gz", hash = "sha256:b946dc5a2308dc1e03efbda80bf1cd64b6053b536851ad519f57ee44401663d2", size = 344405 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/99/01/1eefc235bb79174826b2fa0cad05bc2eab90eae97bf78c765887d7430e46/openai-1.59.4-py3-none-any.whl", hash = "sha256:82113498699998e98104f87c19a890e82df9b01251a0395484360575d3a1d98a", size = 454810 },
]

[[package]]
name = "packaging"
version = "24.2"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/d0/63/68dbb6eb2de9cb10ee4c9c14a0148804425e13c4fb20d61cce69f53106da/packaging-24.2.tar.gz", hash = "sha256:c228a6dc5e932d346bc5739379109d49e8853dd8223571c7c5b55260edc0b97f", size = 163950 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/88/ef/eb23f262cca3c0c4eb7ab1933c3b1f03d021f2c48f54763065b6f0e321be/packaging-24.2-py3-none-any.whl", hash = "sha256:09abb1bccd265c01f4a3aa3f7a7db064b36514d2cba19a2f694fe6150451a759", size = 65451 },
]

[[package]]
name = "pydantic"
version = "2.10.4"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "annotated-types" },
    { name = "pydantic-core" },
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/70/7e/fb60e6fee04d0ef8f15e4e01ff187a196fa976eb0f0ab524af4599e5754c/pydantic-2.10.4.tar.gz", hash = "sha256:82f12e9723da6de4fe2ba888b5971157b3be7ad914267dea8f05f82b28254f06", size = 762094 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/f3/26/3e1bbe954fde7ee22a6e7d31582c642aad9e84ffe4b5fb61e63b87cd326f/pydantic-2.10.4-py3-none-any.whl", hash = "sha256:597e135ea68be3a37552fb524bc7d0d66dcf93d395acd93a00682f1efcb8ee3d", size = 431765 },
]

[[package]]
name = "pydantic-core"
version = "2.27.2"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/fc/01/f3e5ac5e7c25833db5eb555f7b7ab24cd6f8c322d3a3ad2d67a952dc0abc/pydantic_core-2.27.2.tar.gz", hash = "sha256:eb026e5a4c1fee05726072337ff51d1efb6f59090b7da90d30ea58625b1ffb39", size = 413443 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/41/b1/9bc383f48f8002f99104e3acff6cba1231b29ef76cfa45d1506a5cad1f84/pydantic_core-2.27.2-cp313-cp313-macosx_10_12_x86_64.whl", hash = "sha256:7d14bd329640e63852364c306f4d23eb744e0f8193148d4044dd3dacdaacbd8b", size = 1892709 },
    { url = "https://files.pythonhosted.org/packages/10/6c/e62b8657b834f3eb2961b49ec8e301eb99946245e70bf42c8817350cbefc/pydantic_core-2.27.2-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:82f91663004eb8ed30ff478d77c4d1179b3563df6cdb15c0817cd1cdaf34d154", size = 1811273 },
    { url = "https://files.pythonhosted.org/packages/ba/15/52cfe49c8c986e081b863b102d6b859d9defc63446b642ccbbb3742bf371/pydantic_core-2.27.2-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:71b24c7d61131bb83df10cc7e687433609963a944ccf45190cfc21e0887b08c9", size = 1823027 },
    { url = "https://files.pythonhosted.org/packages/b1/1c/b6f402cfc18ec0024120602bdbcebc7bdd5b856528c013bd4d13865ca473/pydantic_core-2.27.2-cp313-cp313-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:fa8e459d4954f608fa26116118bb67f56b93b209c39b008277ace29937453dc9", size = 1868888 },
    { url = "https://files.pythonhosted.org/packages/bd/7b/8cb75b66ac37bc2975a3b7de99f3c6f355fcc4d89820b61dffa8f1e81677/pydantic_core-2.27.2-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:ce8918cbebc8da707ba805b7fd0b382816858728ae7fe19a942080c24e5b7cd1", size = 2037738 },
    { url = "https://files.pythonhosted.org/packages/c8/f1/786d8fe78970a06f61df22cba58e365ce304bf9b9f46cc71c8c424e0c334/pydantic_core-2.27.2-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:eda3f5c2a021bbc5d976107bb302e0131351c2ba54343f8a496dc8783d3d3a6a", size = 2685138 },
    { url = "https://files.pythonhosted.org/packages/a6/74/d12b2cd841d8724dc8ffb13fc5cef86566a53ed358103150209ecd5d1999/pydantic_core-2.27.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:bd8086fa684c4775c27f03f062cbb9eaa6e17f064307e86b21b9e0abc9c0f02e", size = 1997025 },
    { url = "https://files.pythonhosted.org/packages/a0/6e/940bcd631bc4d9a06c9539b51f070b66e8f370ed0933f392db6ff350d873/pydantic_core-2.27.2-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:8d9b3388db186ba0c099a6d20f0604a44eabdeef1777ddd94786cdae158729e4", size = 2004633 },
    { url = "https://files.pythonhosted.org/packages/50/cc/a46b34f1708d82498c227d5d80ce615b2dd502ddcfd8376fc14a36655af1/pydantic_core-2.27.2-cp313-cp313-musllinux_1_1_aarch64.whl", hash = "sha256:7a66efda2387de898c8f38c0cf7f14fca0b51a8ef0b24bfea5849f1b3c95af27", size = 1999404 },
    { url = "https://files.pythonhosted.org/packages/ca/2d/c365cfa930ed23bc58c41463bae347d1005537dc8db79e998af8ba28d35e/pydantic_core-2.27.2-cp313-cp313-musllinux_1_1_armv7l.whl", hash = "sha256:18a101c168e4e092ab40dbc2503bdc0f62010e95d292b27827871dc85450d7ee", size = 2130130 },
    { url = "https://files.pythonhosted.org/packages/f4/d7/eb64d015c350b7cdb371145b54d96c919d4db516817f31cd1c650cae3b21/pydantic_core-2.27.2-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:ba5dd002f88b78a4215ed2f8ddbdf85e8513382820ba15ad5ad8955ce0ca19a1", size = 2157946 },
    { url = "https://files.pythonhosted.org/packages/a4/99/bddde3ddde76c03b65dfd5a66ab436c4e58ffc42927d4ff1198ffbf96f5f/pydantic_core-2.27.2-cp313-cp313-win32.whl", hash = "sha256:1ebaf1d0481914d004a573394f4be3a7616334be70261007e47c2a6fe7e50130", size = 1834387 },
    { url = "https://files.pythonhosted.org/packages/71/47/82b5e846e01b26ac6f1893d3c5f9f3a2eb6ba79be26eef0b759b4fe72946/pydantic_core-2.27.2-cp313-cp313-win_amd64.whl", hash = "sha256:953101387ecf2f5652883208769a79e48db18c6df442568a0b5ccd8c2723abee", size = 1990453 },
    { url = "https://files.pythonhosted.org/packages/51/b2/b2b50d5ecf21acf870190ae5d093602d95f66c9c31f9d5de6062eb329ad1/pydantic_core-2.27.2-cp313-cp313-win_arm64.whl", hash = "sha256:ac4dbfd1691affb8f48c2c13241a2e3b60ff23247cbcf981759c768b6633cf8b", size = 1885186 },
]

[[package]]
name = "python-dotenv"
version = "1.0.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/bc/57/e84d88dfe0aec03b7a2d4327012c1627ab5f03652216c63d49846d7a6c58/python-dotenv-1.0.1.tar.gz", hash = "sha256:e324ee90a023d808f1959c46bcbc04446a10ced277783dc6ee09987c37ec10ca", size = 39115 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/6a/3e/b68c118422ec867fa7ab88444e1274aa40681c606d59ac27de5a5588f082/python_dotenv-1.0.1-py3-none-any.whl", hash = "sha256:f7b63ef50f1b690dddf550d03497b66d609393b40b564ed0d674909a68ebf16a", size = 19863 },
]

[[package]]
name = "shoe-advisor"
version = "0.1.0"
source = { virtual = "." }
dependencies = [
    { name = "faiss-cpu" },
    { name = "numpy" },
    { name = "openai" },
    { name = "python-dotenv" },
]

[package.metadata]
requires-dist = [
    { name = "faiss-cpu", specifier = ">=1.9.0.post1" },
    { name = "numpy", specifier = ">=2.2.1" },
    { name = "openai", specifier = ">=1.59.4" },
    { name = "python-dotenv", specifier = ">=1.0.1" },
]

[[package]]
name = "sniffio"
version = "1.3.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/a2/87/a6771e1546d97e7e041b6ae58d80074f81b7d5121207425c964ddf5cfdbd/sniffio-1.3.1.tar.gz", hash = "sha256:f4324edc670a0f49750a81b895f35c3adb843cca46f0530f79fc1babb23789dc", size = 20372 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl", hash = "sha256:2f6da418d1f1e0fddd844478f41680e794e6051915791a034ff65e5f100525a2", size = 10235 },
]

[[package]]
name = "tqdm"
version = "4.67.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "colorama", marker = "sys_platform == 'win32'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/a8/4b/29b4ef32e036bb34e4ab51796dd745cdba7ed47ad142a9f4a1eb8e0c744d/tqdm-4.67.1.tar.gz", hash = "sha256:f8aef9c52c08c13a65f30ea34f4e5aac3fd1a34959879d7e59e63027286627f2", size = 169737 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl", hash = "sha256:26445eca388f82e72884e0d580d5464cd801a3ea01e63e5601bdff9ba6a48de2", size = 78540 },
]

[[package]]
name = "typing-extensions"
version = "4.12.2"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/df/db/f35a00659bc03fec321ba8bce9420de607a1d37f8342eee1863174c69557/typing_extensions-4.12.2.tar.gz", hash = "sha256:1a7ead55c7e559dd4dee8856e3a88b41225abfe1ce8df57b7c13915fe121ffb8", size = 85321 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/26/9f/ad63fc0248c5379346306f8668cda6e2e2e9c95e01216d2b8ffd9ff037d0/typing_extensions-4.12.2-py3-none-any.whl", hash = "sha256:04e5ca0351e0f3f85c6853954072df659d0d13fac324d0072316b67d7794700d", size = 37438 },
]
